{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bicycle_bell_sed_models.models.crnn import crnn \n",
    "from bicycle_bell_sed_models.models.yamnet_base import yamnet_base\n",
    "from bicycle_bell_sed_models.models.yamnet_lstm_fc import yamnet_lstm_fc\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRNN Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "audioLength = 44100 * 3 # sr*sec\n",
    "rdmAudio = numpy.array([numpy.random.random(audioLength) for _ in range(3)])\n",
    "rdmLabel = numpy.array([numpy.random.randint(0, 2) for _ in range(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"crnn\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " wav_44100_mono_input (InputLay  [(None, None)]      0           []                               \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " padded_wave (PadWaveformLayer)  (None, None)        0           ['wav_44100_mono_input[0][0]']   \n",
      "                                                                                                  \n",
      " log_mel_spectrogram_transform   ((None, None, 128),  0          ['padded_wave[0][0]']            \n",
      " (LogMelSpectrogramTransformLay   (None, None, 96, 1                                              \n",
      " er)                            28))                                                              \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, None, 128, 1  0           ['log_mel_spectrogram_transform[0\n",
      "                                )                                ][0]']                           \n",
      "                                                                                                  \n",
      " time_distributed_convnet_2 (Ti  (None, None, 97, 12  4224       ['reshape[0][0]']                \n",
      " meDistributed)                 8)                                                                \n",
      "                                                                                                  \n",
      " time_distributed_convnet_3 (Ti  (None, None, 97, 12  512        ['time_distributed_convnet_2[0][0\n",
      " meDistributed)                 8)                               ]']                              \n",
      "                                                                                                  \n",
      " time_distributed_convnet_4 (Ti  (None, None, 1, 128  0          ['time_distributed_convnet_3[0][0\n",
      " meDistributed)                 )                                ]']                              \n",
      "                                                                                                  \n",
      " time_distributed_convnet_5 (Ti  (None, None, 1, 128  0          ['time_distributed_convnet_4[0][0\n",
      " meDistributed)                 )                                ]']                              \n",
      "                                                                                                  \n",
      " time_distributed_convnet_6 (Ti  (None, None, 128)   0           ['time_distributed_convnet_5[0][0\n",
      " meDistributed)                                                  ]']                              \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, None, 128)    131584      ['time_distributed_convnet_6[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  (None, None, 128)    131584      ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " time_distributed_fcnet_1 (Time  (None, None, 128)   16512       ['lstm_2[0][0]']                 \n",
      " Distributed)                                                                                     \n",
      "                                                                                                  \n",
      " time_distributed_fcnet_2 (Time  (None, None, 128)   512         ['time_distributed_fcnet_1[0][0]'\n",
      " Distributed)                                                    ]                                \n",
      "                                                                                                  \n",
      " time_distributed_fcnet_3 (Time  (None, None, 1)     129         ['time_distributed_fcnet_2[0][0]'\n",
      " Distributed)                                                    ]                                \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, None)         0           ['time_distributed_fcnet_3[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " time_dissolved (ReduceTimeWrap  (None,)             0           ['flatten_2[0][0]']              \n",
      " per)                                                                                             \n",
      "                                                                                                  \n",
      " class_output (ClassOutput)     (None,)              0           ['time_dissolved[0][0]']         \n",
      "                                                                                                  \n",
      " log_mel_spectrogram_output (Lo  (None, None, 128)   0           ['log_mel_spectrogram_transform[0\n",
      " gMelSpectrogramOutput)                                          ][0]']                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 285,057\n",
      "Trainable params: 284,545\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_crnn = crnn()\n",
    "model_crnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ({wav_44100_mono_input: (None, 132300)}, {class_output: (None,)}), types: ({wav_44100_mono_input: tf.float64}, {class_output: tf.int32})>\n",
      "{'wav_44100_mono_input': <tf.Tensor: shape=(3, 132300), dtype=float64, numpy=\n",
      "array([[0.89141616, 0.34423255, 0.62442053, ..., 0.90638314, 0.56695136,\n",
      "        0.5429709 ],\n",
      "       [0.6035598 , 0.58982039, 0.8125937 , ..., 0.22250388, 0.4883958 ,\n",
      "        0.02650325],\n",
      "       [0.76169059, 0.4786687 , 0.3311342 , ..., 0.13176616, 0.10555902,\n",
      "        0.58250765]])>}\n",
      "{'class_output': <tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 0, 1])>}\n",
      "wav_44100_mono_input\n",
      "class_output\n"
     ]
    }
   ],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices(({'wav_44100_mono_input': rdmAudio}, {'class_output': rdmLabel}))\n",
    "ds = ds.batch(3)\n",
    "\n",
    "print(ds)\n",
    "for xbatch, ybatch in ds:\n",
    "  print(xbatch)\n",
    "  print(ybatch)\n",
    "  for x, y in zip(xbatch, ybatch):\n",
    "    print(x)\n",
    "    print(y)\n",
    "    break\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step - loss: 0.7122 - class_output_loss: 0.7122 - class_output_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21f244b59d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_crnn = crnn()\n",
    "model_crnn.compile(optimizer='adam', \n",
    "    loss=['binary_crossentropy', None],\n",
    "    metrics=[('accuracy',), (None,)],\n",
    "    loss_weights=[1.0, 0.0], \n",
    ")\n",
    "model_crnn.fit(ds, batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step - loss: 0.7379 - class_output_loss: 0.7379 - class_output_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21fefd4c550>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_crnn = crnn()\n",
    "model_crnn.compile(optimizer='adam', \n",
    "    loss={\n",
    "        \"class_output\": 'binary_crossentropy', # last layer name\n",
    "        \"log_mel_spectrogram_output\": None,\n",
    "    },\n",
    "    metrics={\n",
    "        \"class_output\": [\n",
    "            'accuracy',\n",
    "        ],\n",
    "        \"log_mel_spectrogram_output\": [\n",
    "          None,\n",
    "        ],\n",
    "    },\n",
    "    loss_weights={\n",
    "        \"class_output\": 1.0, \n",
    "        \"log_mel_spectrogram_output\": 0.0,\n",
    "    }, \n",
    ")\n",
    "model_crnn.fit(ds, batch_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YAMNet Base Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "audioLength = 16000 * 3 # sr*sec\n",
    "rdmAudio = numpy.array([numpy.random.random(audioLength) for _ in range(3)])\n",
    "rdmLabel = numpy.array([numpy.random.randint(0, 2) for _ in range(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"yamnet_base\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " wav_16000_mono_input (InputLay  [(None, None)]      0           []                               \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " yamnet_wrapper (YAMNetWrapper)  {'scores': (None, N  0          ['wav_16000_mono_input[0][0]']   \n",
      "                                one, 521),                                                        \n",
      "                                 'spectrogram': (No                                               \n",
      "                                ne, None, 64)}                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, None)        0           ['yamnet_wrapper[0][0]']         \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " scores (Layer)                 (None, None)         0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " time_dissolved (ReduceTimeWrap  (None,)             0           ['scores[0][0]']                 \n",
      " per)                                                                                             \n",
      "                                                                                                  \n",
      " class_output (ClassOutput)     (None,)              0           ['time_dissolved[0][0]']         \n",
      "                                                                                                  \n",
      " log_mel_spectrogram_output (Lo  (None, None, 64)    0           ['yamnet_wrapper[0][1]']         \n",
      " gMelSpectrogramOutput)                                                                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_yn_base = yamnet_base()\n",
    "model_yn_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices(({'wav_16000_mono_input': rdmAudio}, {'class_output': rdmLabel}))\n",
    "ds = ds.batch(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 12s 12s/step - loss: 5.1416 - class_output_loss: 5.1416 - class_output_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22046f89f70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_yn_base = yamnet_base()\n",
    "model_yn_base.compile(optimizer='adam', \n",
    "    loss=['binary_crossentropy', None],\n",
    "    metrics=[('accuracy',), (None,)],\n",
    "    loss_weights=[1.0, 0.0], \n",
    ")\n",
    "model_yn_base.fit(ds, batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 11s 11s/step - loss: 5.1416 - class_output_loss: 5.1416 - class_output_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2205f2a2d60>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_yn_base = yamnet_base()\n",
    "model_yn_base.compile(optimizer='adam', \n",
    "    loss={\n",
    "        \"class_output\": 'binary_crossentropy', # last layer name\n",
    "        \"log_mel_spectrogram_output\": None,\n",
    "    },\n",
    "    metrics={\n",
    "        \"class_output\": [\n",
    "            'accuracy',\n",
    "        ],\n",
    "        \"log_mel_spectrogram_output\": [\n",
    "          None,\n",
    "        ],\n",
    "    },\n",
    "    loss_weights={\n",
    "        \"class_output\": 1.0, \n",
    "        \"log_mel_spectrogram_output\": 0.0,\n",
    "    }, \n",
    ")\n",
    "model_yn_base.fit(ds, batch_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YAMNet Extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "audioLength = 16000 * 3 # sr*sec\n",
    "rdmAudio = numpy.array([numpy.random.random(audioLength) for _ in range(3)])\n",
    "rdmLabel = numpy.array([numpy.random.randint(0, 2) for _ in range(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"yamnet_lstm_fc\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " wav_16000_mono_input (InputLay  [(None, None)]      0           []                               \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " yamnet_wrapper (YAMNetWrapper)  {'embeddings': (Non  0          ['wav_16000_mono_input[0][0]']   \n",
      "                                e, None, 1024),                                                   \n",
      "                                 'spectrogram': (No                                               \n",
      "                                ne, None, 64)}                                                    \n",
      "                                                                                                  \n",
      " yamnet_embeddings (Layer)      (None, None, 1024)   0           ['yamnet_wrapper[0][0]']         \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, None, 512)    3147776     ['yamnet_embeddings[0][0]']      \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDistri  (None, None, 512)   262656      ['lstm[0][0]']                   \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " time_distributed_2 (TimeDistri  (None, None, 1)     513         ['time_distributed_1[0][0]']     \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " time_dissolved (ReduceTimeWrap  (None, 1)           0           ['time_distributed_2[0][0]']     \n",
      " per)                                                                                             \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None,)              0           ['time_dissolved[0][0]']         \n",
      "                                                                                                  \n",
      " class_output (ClassOutput)     (None,)              0           ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " log_mel_spectrogram_output (Lo  (None, None, 64)    0           ['yamnet_wrapper[0][1]']         \n",
      " gMelSpectrogramOutput)                                                                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,410,945\n",
      "Trainable params: 3,410,945\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_yn_extended = yamnet_lstm_fc()\n",
    "model_yn_extended.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices(({'wav_16000_mono_input': rdmAudio}, {'class_output': rdmLabel}))\n",
    "ds = ds.batch(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_train_function.<locals>.train_function at 0x0000022091CE3A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_train_function.<locals>.train_function at 0x0000022091CE3A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 12s 12s/step - loss: 1.6393 - class_output_loss: 1.6393 - class_output_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22092e8aac0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_yn_extended = yamnet_lstm_fc()\n",
    "model_yn_extended.compile(optimizer='adam', \n",
    "    loss=['binary_crossentropy', None],\n",
    "    metrics=[('accuracy',), (None,)],\n",
    "    loss_weights=[1.0, 0.0], \n",
    ")\n",
    "model_yn_extended.fit(ds, batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_train_function.<locals>.train_function at 0x000002201A5C6310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_train_function.<locals>.train_function at 0x000002201A5C6310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 12s 12s/step - loss: 10.2833 - class_output_loss: 10.2833 - class_output_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x220825e7a00>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_yn_extended = yamnet_lstm_fc()\n",
    "model_yn_extended.compile(optimizer='adam', \n",
    "    loss={\n",
    "        \"class_output\": 'binary_crossentropy', # last layer name\n",
    "        \"log_mel_spectrogram_output\": None,\n",
    "    },\n",
    "    metrics={\n",
    "        \"class_output\": [\n",
    "            'accuracy',\n",
    "        ],\n",
    "        \"log_mel_spectrogram_output\": [\n",
    "          None,\n",
    "        ],\n",
    "    },\n",
    "    loss_weights={\n",
    "        \"class_output\": 1.0, \n",
    "        \"log_mel_spectrogram_output\": 0.0,\n",
    "    }, \n",
    ")\n",
    "model_yn_extended.fit(ds, batch_size=3)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2647ea34e536f865ab67ff9ddee7fd78773d956cec0cab53c79b32cd10da5d83"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
